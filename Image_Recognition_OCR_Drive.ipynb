{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMEeIIx8av3x"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdOy2UAFbdKz"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.4.0\n",
        "!pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0\n",
        "!pip install imageai --upgrade\n",
        "!pip install imageai.Detection\n",
        "!pip install cnocr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select only one model, I prefer you use yolo.h5 one as it is default and work with the code. You may need to change code for directory etc\n"
      ],
      "metadata": {
        "id": "fbJN9m61275P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5SvOKlvEJn6"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "URL = \"https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/DenseNet-BC-121-32.h5\"\n",
        "response = wget.download(URL, \"DenseNet121.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yAWW_fzdWqY"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "URL = \"https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5\"\n",
        "response = wget.download(URL, \"yolo.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKj7JvHhmOOf"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "URL = \"https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo-tiny.h5\"\n",
        "response = wget.download(URL, \"yolo-tiny.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHQDudqGpVZr"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "URL = \"https://github.com/OlafenwaMoses/ImageAI/releases/download/essentials-v5/resnet50_coco_best_v2.1.0.h5\"\n",
        "response = wget.download(URL, \"resnet50_coco_best_v2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LKWCPrszRZS"
      },
      "outputs": [],
      "source": [
        "def initialOCR():\n",
        "    from cnocr import CnOcr\n",
        "    ocr = CnOcr(det_model_name='en_PP-OCRv3_det', rec_model_name='en_PP-OCRv3')\n",
        "    return ocr\n",
        "\n",
        "ocr = initialOCR()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQV450JF7xZY"
      },
      "outputs": [],
      "source": [
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "execution_path = os.getcwd()\n",
        "detector = ObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath( os.path.join(execution_path , \"yolo.h5\"))\n",
        "detector.loadModel()\n",
        "\n",
        "GuIDList = []\n",
        "newList = []\n",
        "newList_Ocr = []\n",
        "src = r'/content/drive/MyDrive/office_test'\n",
        "path_img = r'/content/drive/MyDrive/office_test'\n",
        "dir_list = os.listdir(path_img)\n",
        "newGuIDPath = path_img + \"/\" + \"GuID.txt\"\n",
        "newOcrPath = path_img + \"/\" + \"OCR.txt\"\n",
        "newRecogrPath = path_img + \"/\" + \"Recognition.txt\"\n",
        "\n",
        "for fname in os.listdir(src):\n",
        "  # build the path to the folder\n",
        "  newtempfname = fname\n",
        "  newtempfname = \"insta_\" +newtempfname\n",
        "  folder_path = os.path.join(src, fname)\n",
        "  GuIDList.append(fname)\n",
        "  if os.path.isdir(folder_path):\n",
        "    # we are sure this is a folder; now lets iterate it\n",
        "    print(os.listdir(folder_path))\n",
        "    for file_name in os.listdir(folder_path):\n",
        "      file_path = os.path.join(folder_path, file_name)\n",
        "      print(file_path)\n",
        "      dir_list = os.listdir(file_path)\n",
        "      path_img = file_path\n",
        "      print(dir_list)\n",
        "      textFile_output = path_img + '/' + \"ocr.txt\"\n",
        "      textFile_output_recog = path_img + '/' + \"recognition.txt\"\n",
        "      file_list_data = path_img + '/' + \"file_list.txt\"\n",
        "      newTempToSave = \"\"\n",
        "      newTempToSaveOcr = \"\"\n",
        "\n",
        "\n",
        "      if( (os.path.exists(textFile_output) ==False)  and (os.path.exists(textFile_output_recog) == False)  ):\n",
        "        for i in dir_list:\n",
        "\n",
        "          new_path = ''\n",
        "          new_path = path_img + '/' + i\n",
        "\n",
        "\n",
        "          j = \"new_\" + i\n",
        "          newPath_img = path_img + '/' + j\n",
        "\n",
        "\n",
        "          out = ocr.ocr(new_path)\n",
        "          detections = detector.detectObjectsFromImage(new_path, newPath_img, minimum_percentage_probability=30)\n",
        "          plt.clf()\n",
        "          img_color = cv2.imread(new_path,1)\n",
        "          img_color2 = cv2.imread(newPath_img,1)\n",
        "          f, axarr = plt. subplots(2)\n",
        "          axarr[0]. imshow(img_color)\n",
        "          axarr[1]. imshow(img_color2)\n",
        "          plt.show()\n",
        "\n",
        "\n",
        "          #To get into each GuID --> UserName_of_Social_handle and then RUN the algorithm.\n",
        "          for eachObject in detections:\n",
        "            newTempToSave = newTempToSave + \" \" + eachObject[\"name\"]\n",
        "            print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
        "            print(\"--------------------------------\")\n",
        "          for ocr_i in range(len(out)):\n",
        "            newTempToSaveOcr = newTempToSaveOcr + \" \" + out[ocr_i]['text']\n",
        "            print(out[ocr_i]['text'])\n",
        "          print(newTempToSave)\n",
        "          print(newTempToSaveOcr)\n",
        "\n",
        "      print(\"After Whole User Data Read!\")\n",
        "      newList.append(newTempToSave)\n",
        "      newList_Ocr.append(newTempToSaveOcr)\n",
        "      # now you can apply any function assuming it is a file\n",
        "      # or double check it if needed as `os.path.isfile(file_path)`\n",
        "\n",
        "      print(newTempToSaveOcr)\n",
        "      print(newTempToSave)\n",
        "      with open(textFile_output, 'a+') as fp:\n",
        "        fp.write(newTempToSaveOcr)\n",
        "      with open(textFile_output_recog, 'a+') as fp:\n",
        "        fp.write(newTempToSave)\n",
        "      with open(file_list_data, 'a+') as fp:\n",
        "        fp.write('\\n'.join(dir_list))\n",
        "\n",
        "\n",
        "newGuIDPath = path_img + \"/\" + \"GuID.txt\"\n",
        "newOcrPath = path_img + \"/\" + \"OCR.txt\"\n",
        "newRecogrPath = path_img + \"/\" + \"Recognition.txt\"\n",
        "\n",
        "with open(newGuIDPath, 'a+') as fp:\n",
        "  fp.write('\\n'.join(GuIDList))\n",
        "with open(newOcrPath, 'a+') as fp:\n",
        "  fp.write('\\n'.join(newList_Ocr))\n",
        "with open(newRecogrPath, 'a+') as fp:\n",
        "  fp.write('\\n'.join(newList))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}